\chapter{Conclusion}

Our project have demonstrated distributed vision-based target tracking control using mobile robots. We have achieved the project goals mentioned in Section 2.3 – that is to design a target identification (detect and locate) module based on RGB image features obtained from a vision sensor, to design a target tracking algorithm based on robot model linearization, to design a leader-follower formation control algorithm based on depth and image features provided from the target identification module, to design a state machine to coordinate target identification module and target control module and communications between robots, and to integrate and validate the proposed distributed controls through experimentation in a controlled lab environment. 
All the while, there were still problems with the upcoming design. The QBot2 does not contain enough processing power for the image processing that we desired – therefore, blob detection was used. A better target recognition algorithm, such as hough transforms, allows a more robust target detection method. Failures, such as the target being misclassified or kinematic issues, were also noted and fixed during implementation. The Qbot occasionally would reset and move backwards once a target object was found. We believe this may be an issue with misclassification or a faulty kinematic model. Another problem with the QBot concerned the updating of RGB and IR images. The middleware for the Simulink design block that increased a tick for every image update occasionally would not change. This prevented us from keeping track each time image processing was finished and delayed search mode.
Overall, this project demonstrated that minimized local communication and formation between robots is feasible. Future work, such as obstacle avoidance and improved image processing, can still be researched.